State-of-the-art within machine learning includes multiple areas were technologies as OpenAI, Semantic segmentation or image generation has become increasingly popular. 
Machine learning has a major focus in healthcare to improve and streamline systems. Examples of current research in this area are deepmind, which recently published models for the COVID-19 virus using AlphaFold, a system for extracting protein structures. Feature selection has become increasingly popular and data processing has increased significantly with big data. In Feature Selection: A Data Perspective, 2017 is shown to reduce irrelevant data.

The algorithms used during the project are as follows. You can see the different models for regression and classification as well as an example of the hyper-parameters used for the project.

The project was implemented with the following model. The data is loaded into the project, transformed and processed which includes normalization and possible conversions of the dataset if needed. The number of features is reduced using PCA to create a more general model and reduce irrelevant features. Then feature selection is applied and picks out the features so the target data affects the most. Then the model is trained on the training set with different hyperparameters and validated with the help of K-folding. Finally, the top 5 best models are presented with their mean and variance.

During the project different models are visualized. Among these is a box plot and scatter matrix to visualize the distribution and get an idea of ​​what the dataset contains. Visualizations for PCA and what features are in the dataset are presented. Finally, the data is presented in the form of a confusion matrix and a plot depending on classification or regression. This gives a picture of how the model performed and cases such as the UN or FP are shown when this is easily missed if you only present the value that the test set has presented. The last pictures we can see how the models performed and the interesting thing can be how the top part shows if the model starts to overfit.


The models performed relatively well, but limitations in, among other things, the amount of data may have had a negative impact on the result. Against previous work such as the International evaluation of an AI system for breast cancer screening, the models performed slightly worse by 7% compared to 2.7% but better than the model by 9%